---
title: "Assignment 1: Analyzing an Obesity dataset"
author: William Schaafsma, Hau Nguyen, Qingyu Meng
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
       highlight: textmate
       theme: flatly
       number_sections: TRUE
       toc: TRUE
       toc_float:
         collapsed: TRUE
         smooth_scroll: FALSE
---

# Introduction and Research Question

In this assignment an obesity dataset, retrieved from [Palechor & Manotas, 2019](https://www-sciencedirect-com.proxy.library.uu.nl/science/article/pii/S2352340919306985?via%3Dihub) will be analyzed. The data gathered for this paper comes from individuals that live in Peru, Mexico and Colombia. It's stated that 23% of the data is "real" and that 77% has been synthetically generated.

The goal for this assignment is to build a model that most accurately predicts the BMI of *new* patients. Understanding which predictors have great influence for one's BMI is favorable for policymakers regarding national health. Moreover, patients get more understanding of their own health.

We will work in an exploratory manner. Thus, in this assignment we are particularly interested in: 'What predictors show the greatest influence regarding a person's BMI?'

# Packages

The following libraries are required to run this program succesfully.
```{r libraries, warning = FALSE, message = FALSE}
library(ggplot2)
library(corrplot)
library(dplyr)
library(knitr)
library(tidyverse)
library(mice)
library(magrittr)
library(readr)
library(caret)
library(leaps)
```


# Loading the dataset & set seed

First we load the data and set the seed in order to generate a reproducible result.

```{r, message=FALSE}
# loading data
obese <- read_csv("ObesityDataSet_raw_and_data_sinthetic (2)/ObesityDataSet_raw_and_data_sinthetic.csv")

# set the seed
set.seed(1705)
```

# Processing of the data

We want to include BMI as a dependent variable in our model. Thus we have to derive BMI from Weight and Height with the formula:  $BMI = Weight / Height^2$

```{r, message=FALSE, }
# calculating bmi from height and weight
Bmi <- data.frame(Bmi = (obese$Weight / (obese$Height^2)))

# adding bmi to the original dataframe
obese_mid <- cbind(obese, Bmi)

# removing *NObeyesdad* since we don't need the variable
obese_complete <- select(obese_mid, -NObeyesdad)
```

# Splitting the data into train, validation & test

In order to evaluate the performance of the model we will build later on, we have to split the data into three partitions: Train, Test, Validation. The data will be split in a way that ~70% of the data is used for training the model, ~20% for validating the model and ~10% for testing the model.

```{r, message=FALSE}
# partition of training
part_train <- createDataPartition(obese_complete$Bmi, p = .7, 
                                  list = FALSE, 
                                  times = 1)

# creation of training data
obese_train <- obese_complete[part_train,]

# remainder for validation and testing
part_test_val <- obese_complete[-part_train,]

# partition of validation
part_val <- createDataPartition(part_test_val$Bmi, p = .66, 
                                  list = FALSE, 
                                  times = 1)
# creation of validation data
obese_val <- part_test_val[part_val,]

# creation of test data
obese_test  <- part_test_val[-part_val,]
```

# Explaining the variables

**WARNING:** the simulated data created incorrect data. Particularly, it treated categorical data as numeric data and therefore wrongfully imputed these data. However, in this assignment we will treat these data as if they were numeric since converting the datatypes causes loads of parsing errors. This problem affects the following variables: *FCVC, NCP, CH2O, FAF* and *TUE*.


In this section, an elaboration on the variables is given. For starters, the categorical variable **Gender** consists of two categories representing one's gender: male or female.

Next is the continuous variable **Age** that only contains integers of every person's age. 

Then the continuous variable **Height** that contains floating values for a person's Height, measured in meters.

Then there's another continuous variable **Weight** that also contains floating values for a person's weight, measured in Kilograms (KG).

There's also the dichotomous variable **family_history_with_overweight** which controls for possible genetic predisposition for a high BMI. 

Next is another dichotomous variable **FAVC** that represents whether a person frequently consumes high caloric foods.

Then a "numeric" variable **FCVC** which represents the frequency of consuming vegetables. 

Then there's another "numeric" variable **NCP** that accounts for the number of main meals each day.

Next is the categorical variable **CAEC** consisting of four categories representing the consumption of foods between meals: No, Sometimes, Frequently, Always.

Then there is a dichotomous variable **SMOKE** that represents whether a person smokes

Next is a "numeric" variable **CH2O** which represents the amount of water a person drinks each day.

Next is another dichotomous variable **SCC** that accounts for calorie checking.

Then there's a "numeric" variable **FAF** which represents the frequency of physical activity of a person.

Next is another "numeric" variable **TUE** which represents the amount a person spends on it's devices such as a phone.

Then there is the categorical variable **CALC** consisting of four categories representing a person's alcohol intake: Nothing, Sometimes, Frequently, Always. 

Finally, there is the categorical variable **MTRANS** consisting of five categories representing a person's most used public transport: Automobile, Motorbike, Bike, Public Transportation and Walking.


# Getting to know the data

In order to work with a dataset, we need to understand the dataset. First, let's check wether there are missing data in our dataset. To do this we use the `mice` package.

```{r, message=FALSE}
md.pattern(obese_complete)
```

Fortunately, we can conclude that our dataset contains no missing values. Furthermore, the figure shows that our dataset holds 17 variables and 2111 observations. 

Now, let us see the head and the summary of the dataset

```{r head}
head(obese_complete) %>% 
  knitr::kable(format = "markdown", digits= 1, padding = 30, align = 'c')
```

```{r}
summary(obese_complete)
```
From the head and summary function we can tell that the data has loaded as expected and that the datatypes are in line with how we described them in section **"Explaining the variables"**. 

# Correlations

In this section we will try to look for strong correlations between the predicting variables and our dependent variable BMI. Acknowledging the fact for BMI being a derived variable, we will not take *Height* and *Weight* into consideration since this will cause high levels of multicollinearity. 



# Model training

For the sake of model training we will start by a simple linear model that contains just one predictor. In this case we will pick the variable *Age*.

```{r}
model_1 <- lm(Bmi ~ Age, data = obese_train)
summary(model_1)
```
```{r}
model_2 <- lm(Bmi ~ Age + CALC + FAVC + family_history_with_overweight, data = obese_train)
summary(model_2)
```


# Best model selection & model comparison

Building a model by trial and error takes a lot of time and working memory. It's best to build a model based on some algorithm. For example we can use *forward selection*. This method start with no predictors and then iteratively adds contributive predictors untill there's no significant improvement.

```{r}
# start building a model by forward selection
model_forward <- regsubsets(Bmi ~., data = obese_train, 
                                 method = "forward")

summary(model_forward)
```


# Model evaluation & VIF

# Checking assumptions

# Visualizations

# Answering research question

# Discussion & Limitations

# Sources
